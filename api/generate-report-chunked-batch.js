// generate-report-chunked.js ã® Step 3 éƒ¨åˆ†
// Batch APIã‚’ä½¿ç”¨ã—ãŸAIåˆ†æã®å®Ÿè£…

const OpenAI = require('openai');
const fs = require('fs').promises;

async function handleStep3WithBatch(progress, orderId, messages, fortune) {
  const openai = new OpenAI({
    apiKey: process.env.OPENAI_API_KEY
  });
  
  // Batch IDãŒæ—¢ã«å­˜åœ¨ã™ã‚‹å ´åˆã¯çµæœã‚’ç¢ºèª
  if (progress.data.aiBatchId) {
    console.log('ğŸ” Checking batch status...');
    
    try {
      const batch = await openai.batches.retrieve(progress.data.aiBatchId);
      console.log(`ğŸ“Š Batch status: ${batch.status}`);
      
      if (batch.status === 'completed') {
        console.log('âœ… Batch completed! Retrieving results...');
        
        // çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
        const outputFile = await openai.files.content(batch.output_file_id);
        
        // ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›
        let content;
        if (typeof outputFile === 'string') {
          content = outputFile;
        } else if (Buffer.isBuffer(outputFile)) {
          content = outputFile.toString('utf-8');
        } else {
          // ReadableStreamã®å ´åˆ
          const chunks = [];
          for await (const chunk of outputFile) {
            chunks.push(chunk);
          }
          content = Buffer.concat(chunks).toString('utf-8');
        }
        
        // çµæœã‚’ãƒ‘ãƒ¼ã‚¹
        const lines = content.split('\n').filter(line => line.trim());
        for (const line of lines) {
          const result = JSON.parse(line);
          if (result.custom_id === `order_${orderId}`) {
            if (result.response && result.response.body) {
              const aiContent = result.response.body.choices[0].message.content;
              progress.data.aiInsights = JSON.parse(aiContent);
              progress.currentStep++;
              console.log('âœ… AI insights extracted successfully');
              return { completed: true };
            } else if (result.error) {
              console.error('âŒ Batch request failed:', result.error);
              progress.data.aiInsights = null;
              progress.currentStep++;
              return { completed: true, error: result.error };
            }
          }
        }
        
      } else if (batch.status === 'failed' || batch.status === 'expired') {
        console.log(`âŒ Batch ${batch.status}`);
        progress.data.aiInsights = null;
        progress.currentStep++;
        return { completed: true, error: batch.status };
        
      } else {
        // ã¾ã å‡¦ç†ä¸­ (validating, in_progress, finalizing)
        const waitTime = Date.now() - new Date(progress.data.aiBatchStartTime).getTime();
        const waitMinutes = Math.floor(waitTime / 60000);
        const waitSeconds = Math.floor((waitTime % 60000) / 1000);
        
        console.log(`â³ Batch ${batch.status} (${waitMinutes}m ${waitSeconds}s elapsed)`);
        
        // 5åˆ†ä»¥ä¸Šå¾…ã£ãŸå ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆæœ¬ç•ªã§ã¯30åˆ†ç¨‹åº¦ã¾ã§å¾…ã£ã¦ã‚‚è‰¯ã„ï¼‰
        if (waitTime > 300000) { // 5åˆ†
          console.log('â° Timeout - skipping AI analysis');
          progress.data.aiInsights = null;
          progress.currentStep++;
          return { completed: true, timeout: true };
        }
        
        return { 
          completed: false, 
          status: batch.status,
          waitTime: waitTime 
        };
      }
      
    } catch (error) {
      console.error('âŒ Error checking batch:', error);
      // ãƒãƒƒãƒIDãŒç„¡åŠ¹ãªå ´åˆã¯æ–°è¦ä½œæˆ
      if (error.status === 404) {
        console.log('ğŸ”„ Batch not found, creating new one...');
        delete progress.data.aiBatchId;
        return handleStep3WithBatch(progress, orderId, messages, fortune);
      }
      throw error;
    }
    
  } else {
    // åˆå›: ãƒãƒƒãƒã‚¸ãƒ§ãƒ–ã‚’ä½œæˆ
    console.log('ğŸš€ Creating AI batch job...');
    
    try {
      // ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚µãƒ³ãƒ—ãƒ«ã‚’ä½œæˆï¼ˆæœ€æ–°15ä»¶ï¼‰
      const recentMessages = messages.slice(-15);
      const conversationSample = recentMessages.map(m => 
        `${m.isUser ? 'ãƒ¦ãƒ¼ã‚¶ãƒ¼' : 'ç›¸æ‰‹'}: ${m.text}`
      ).join('\n');
      
      // ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
      const prompt = `ä»¥ä¸‹ã®LINEãƒˆãƒ¼ã‚¯å±¥æ­´ã‚’åˆ†æã—ã€æ‹æ„›ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã¨ã—ã¦éå¸¸ã«è©³ç´°ãªãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ä¼šè©±ã‚µãƒ³ãƒ—ãƒ«ï¼š
${conversationSample}

åŸºæœ¬åˆ†æçµæœï¼š
${JSON.stringify(fortune, null, 2)}

ä»¥ä¸‹ã®JSONå½¢å¼ã§ã€éå¸¸ã«è©³ç´°ãªåˆ†æçµæœã‚’è¿”ã—ã¦ãã ã•ã„ï¼š
{
  "emotionalState": {
    "user": "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„Ÿæƒ…çŠ¶æ…‹ã®è©³ç´°åˆ†æï¼ˆ200æ–‡å­—ä»¥ä¸Šï¼‰",
    "partner": "ç›¸æ‰‹ã®æ„Ÿæƒ…çŠ¶æ…‹ã®è©³ç´°åˆ†æï¼ˆ200æ–‡å­—ä»¥ä¸Šï¼‰",
    "compatibility": "æ„Ÿæƒ…çš„ãªç›¸æ€§ã®è©³ç´°è©•ä¾¡ï¼ˆ200æ–‡å­—ä»¥ä¸Šï¼‰"
  },
  "communicationStyle": {
    "userPattern": "ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³è©³ç´°ï¼ˆ150æ–‡å­—ä»¥ä¸Šï¼‰",
    "partnerPattern": "ç›¸æ‰‹ã®ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³è©³ç´°ï¼ˆ150æ–‡å­—ä»¥ä¸Šï¼‰",
    "recommendations": ["æ”¹å–„ææ¡ˆ1", "æ”¹å–„ææ¡ˆ2", "æ”¹å–„ææ¡ˆ3"]
  },
  "futureOutlook": [
    {
      "month": "1ãƒ¶æœˆå¾Œ",
      "prediction": "è©³ç´°ãªäºˆæ¸¬å†…å®¹ï¼ˆ150æ–‡å­—ä»¥ä¸Šï¼‰",
      "keyEvents": ["é‡è¦ã‚¤ãƒ™ãƒ³ãƒˆ1", "é‡è¦ã‚¤ãƒ™ãƒ³ãƒˆ2"]
    },
    {
      "month": "3ãƒ¶æœˆå¾Œ",
      "prediction": "è©³ç´°ãªäºˆæ¸¬å†…å®¹ï¼ˆ150æ–‡å­—ä»¥ä¸Šï¼‰",
      "keyEvents": ["é‡è¦ã‚¤ãƒ™ãƒ³ãƒˆ1", "é‡è¦ã‚¤ãƒ™ãƒ³ãƒˆ2"]
    }
  ],
  "uniqueInsights": "ã“ã®äºŒäººç‰¹æœ‰ã®éå¸¸ã«è©³ç´°ãªæ´å¯Ÿï¼ˆ300æ–‡å­—ä»¥ä¸Šï¼‰"
}`;
      
      // ãƒãƒƒãƒãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ä½œæˆ
      const batchRequest = {
        custom_id: `order_${orderId}`,
        method: "POST",
        url: "/v1/chat/completions",
        body: {
          model: "gpt-4o-mini",
          messages: [
            {
              role: "system",
              content: "ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªæ‹æ„›ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼ã§ã€å¿ƒç†å­¦ã®å°‚é–€çŸ¥è­˜ã‚’æŒã¡ã€æ—¥æœ¬ã®æ‹æ„›æ–‡åŒ–ã«ç²¾é€šã—ã¦ã„ã¾ã™ã€‚"
            },
            {
              role: "user",
              content: prompt
            }
          ],
          temperature: 0.8,
          max_tokens: 3000,
          response_format: { type: "json_object" }
        }
      };
      
      // JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
      const jsonlContent = JSON.stringify(batchRequest);
      const tempPath = `/tmp/batch_${orderId}_${Date.now()}.jsonl`;
      await fs.writeFile(tempPath, jsonlContent);
      
      // OpenAIã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
      const file = await openai.files.create({
        file: await fs.readFile(tempPath),
        purpose: "batch"
      });
      console.log(`ğŸ“ File uploaded: ${file.id}`);
      
      // ãƒãƒƒãƒã‚¸ãƒ§ãƒ–ã‚’ä½œæˆ
      const batch = await openai.batches.create({
        input_file_id: file.id,
        endpoint: "/v1/chat/completions",
        completion_window: "24h"
      });
      
      console.log(`âœ… Batch created: ${batch.id}`);
      console.log(`   Initial status: ${batch.status}`);
      
      // é€²æ—ã«ä¿å­˜
      progress.data.aiBatchId = batch.id;
      progress.data.aiBatchStartTime = new Date().toISOString();
      progress.data.aiBatchFileId = file.id;
      
      // ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
      await fs.unlink(tempPath).catch(() => {});
      
      return { 
        completed: false, 
        batchCreated: true,
        batchId: batch.id 
      };
      
    } catch (error) {
      console.error('âŒ Error creating batch:', error);
      // ãƒãƒƒãƒä½œæˆã«å¤±æ•—ã—ãŸå ´åˆã¯AIãªã—ã§ç¶šè¡Œ
      progress.data.aiInsights = null;
      progress.currentStep++;
      return { completed: true, error: error.message };
    }
  }
}

module.exports = { handleStep3WithBatch };